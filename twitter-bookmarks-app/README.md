# Twitter Bookmarks Processing App

Transform your Twitter bookmarks into actionable knowledge using LLMs.

## Features

- ğŸ“š Fetch up to 800 of your most recent Twitter bookmarks
- ğŸ’¾ Save and load bookmarks locally
- ğŸ“Š View bookmark statistics and topic analysis
- ğŸ“ Export bookmarks to Markdown
- ğŸš€ **NEW: Twillot Integration (Rich Bookmark Data)**
  - Automated browser scraping with Playwright + Twillot extension
  - Complete tweet text (not truncated)
  - Media URLs (images, videos, GIFs)
  - Thread content
  - Full engagement metrics
  - No API rate limits!
  - Import from Twillot export files (JSON/CSV)
- ğŸ§  **Intelligent Topic Analysis**
  - Automatic categorization into topics (AI/ML, Programming, Tools, etc.)
  - Keyword extraction and frequency analysis
  - Knowledge graph visualization (Mermaid diagrams)
  - Find connections between related bookmarks
- ğŸ”— **NEW: Automatic URL Expansion**
  - Expands t.co shortened links to real URLs
  - Extracts metadata (title, description, images)
  - Special handling for GitHub repos, YouTube videos
  - Rich bookmark exports with actual content
- ğŸ¤– **Smart Processing by Topic** with your choice of LLM:
  - OpenAI (GPT-4, o3 models)
  - Anthropic (Claude)
  - Google Gemini
- ğŸ¯ Advanced Processing Modes:
  - **Topic-specific analysis**: Process bookmarks grouped by subject
  - **Topic overview**: Get insights across all your interests
  - **Learning paths**: Create structured study plans from educational content
  - **Tool comparison**: Compare similar tools and services
  - **Deep dive analysis**: In-depth exploration of specific topics
- ğŸ”„ Bookmark management:
  - Pagination support for fetching all bookmarks
  - Unbookmark processed tweets to avoid 800 limit

## Quick Start

### 1. Install Dependencies

```bash
# Create virtual environment
python3 -m venv venv
source venv/bin/activate  # On Windows: venv\Scripts\activate

# Install required packages
pip install -r requirements.txt

# For Twillot integration (optional but recommended):
playwright install chromium
```

### 2. Configure Twitter App

1. Go to [Twitter Developer Portal](https://developer.twitter.com)
2. Navigate to your project and app
3. Enable OAuth 2.0 in User Authentication Settings:
   - App Type: Web App or Native App
   - Callback URL: `http://127.0.0.1:3000/callback`
   - Website URL: `http://127.0.0.1:3000`
   - Scopes: `tweet.read`, `users.read`, `bookmark.read`, `offline.access`

### 3. Set Up Environment

```bash
# Copy example environment file
cp .env.example .env

# Edit .env with your credentials
# At minimum, add your TWITTER_CLIENT_ID
```

### 4. Run the App

```bash
python main.py
```

## Usage

1. **First Run**: The app will open a browser for Twitter authentication
2. **Main Menu Options**:
   - **Fetch new bookmarks** - Get latest bookmarks (1 request per 15 minutes on free tier)
   - **Load saved bookmarks** - Load previously fetched bookmarks
   - **View statistics** - See bookmark counts and basic stats
   - **Export to Markdown** - Save bookmarks for reading
   - **Analyze topics** ğŸ†• - Discover topics, keywords, and connections in your bookmarks
   - **Smart processing** ğŸ†• - Process bookmarks intelligently by topic with LLM
   - **Expand URLs** ğŸ†• - Expand t.co links and extract metadata from websites
   - **Configure LLM** - Set up your preferred AI provider
   - **Reset pagination** - Start fetching from the beginning
   - **Unbookmark tweets** - Remove processed bookmarks from Twitter

### Smart Processing Modes

When you select "Smart processing", you can choose from:

1. **Process by Topic** - Select a specific topic (AI/ML, Programming, etc.) to analyze
2. **Topic Overview** - Get a comprehensive analysis of all your bookmark topics
3. **Learning Path** - Generate a structured curriculum from educational bookmarks
4. **Tool Comparison** - Compare similar tools and services mentioned in bookmarks
5. **Deep Dive** - In-depth analysis of a topic with related content

## Twillot Integration (Recommended)

For richer bookmark data, use the Twillot integration instead of the Twitter API:

### Option 1: Automated Scraping (Best)

1. Install Playwright: `playwright install chromium`
2. Download the [Twillot Chrome Extension](https://chromewebstore.google.com/detail/twillot/cedokfdbikcoefpkofjncipjjmffnknf)
3. Extract the extension to `./extensions/twillot/`
4. Run the app and select **"Fetch via Twillot"**

The app will:
- Open a browser with Twillot loaded
- Let you log in to Twitter (first time only)
- Automatically scroll and load all bookmarks
- Extract rich data including media, threads, metrics

### Option 2: Import Twillot Export

1. Install Twillot extension in your browser
2. Export bookmarks from Twillot (JSON or CSV)
3. Run the app and select **"Import Twillot export file"**

### Why Twillot vs Twitter API?

| Feature | Twitter API | Twillot |
|---------|-------------|---------|
| Tweet text | Often truncated | Complete |
| Media | Not included | Full URLs |
| Threads | Not included | Complete |
| Rate limits | 1 req/15 min | None |
| Account risk | None | None* |

*Twillot runs in your browser like normal browsing.

## LLM Configuration

The app supports multiple LLM providers. You can either:
- Set API keys in the `.env` file
- Enter them when prompted in the app

### Supported Providers:
- **OpenAI**: Uses GPT-3.5-turbo by default
- **Anthropic**: Uses Claude 3 Haiku by default  
- **Google Gemini**: Uses Gemini 1.5 Flash by default (has free tier!)

## Rate Limits

- **Free Twitter API**: 1 bookmark request every 15 minutes (up to 800 bookmarks)
- **LLM APIs**: Varies by provider and plan

## File Structure

```
twitter-bookmarks-app/
â”œâ”€â”€ main.py              # Main application with smart processing
â”œâ”€â”€ twitter_auth.py      # OAuth 2.0 authentication
â”œâ”€â”€ bookmarks_fetcher.py # Bookmark fetching and management
â”œâ”€â”€ bookmark_analyzer.py # Topic analysis and knowledge graphs
â”œâ”€â”€ link_expander.py     # URL expansion and metadata extraction
â”œâ”€â”€ twillot_scraper.py   # Twillot automation with Playwright ğŸ†•
â”œâ”€â”€ llm_providers.py     # Modular LLM providers (supports o3!)
â”œâ”€â”€ requirements.txt     # Python dependencies
â”œâ”€â”€ .env.example         # Example environment variables
â”œâ”€â”€ CLAUDE.md           # Developer documentation
â”œâ”€â”€ README.md           # This file
â””â”€â”€ extensions/          # Chrome extensions (Twillot) ğŸ†•
    â””â”€â”€ twillot/         # Extracted Twillot extension
```

## Troubleshooting

1. **Authentication Issues**: 
   - Ensure your Twitter app has OAuth 2.0 enabled
   - Check that the redirect URI matches exactly

2. **Rate Limit Errors**:
   - Free tier allows only 1 request per 15 minutes
   - Wait before making another request

3. **LLM Errors**:
   - Verify your API keys are correct
   - Check your API usage limits

## Security Notes

- Never commit your `.env` file
- Tokens are saved locally in `tokens.json` (git-ignored)
- API keys are masked when entered in the app

## Future Enhancements

- [ ] Batch processing for more than 800 bookmarks
- [ ] Advanced categorization and tagging
- [ ] Export to Notion, Obsidian, etc.
- [ ] Scheduled bookmark fetching
- [ ] Web UI interface